/*
 
# SmartOS Dataset Library

This library is specifically written to manage and manipulate
datasets in SmartOS. A dataset is a binary blob which is 
presented to a virtual machine as a local storage volume;
The dataset usually contains an operating system.

When a dataset is installed, it is downloaded from the appropriate
server or service and piped to zfs. custom properties are set. Those
custom properties include "dsadm:urn" and "dsasdm:uuid", which
represent the urn and uuid of the dataset that was installed.
This can be used to identify the dataset if the dsadm database is
missing. 

The database is a collection of manifests stored in /var/lib/dsadm
Those manifests are saved in order to be able to have local information
about the dataset, and its requirements.

If at any time the database is destroyed, you can try and run the
repair.sh tool which will - in a rather brutish manner - attempt
to rebuild the database by comparing the uuids of existing datasets 
with the ones available in dsapi.

Datasets may be destroyed only if they do not have any children.
Children includes 'snapshots' and 'clones' of those snapshots.
If any children other than the snapshot of the dataset itself
exists, then you will not be able to remove the dataset from the 
compute node. 


# To Implement

* Destroy a dataset
* Used By - Tells you which vms are using a particular dataset

*/

var assert = require('assert');
var url = require('url');
var fs = require('fs');
var spawn = require('child_process').spawn;
var http = require('http');
var https = require('https');
var dns = require('dns');
var zfs = require('./zfs');
var common = require('./common'); 
var log = common.log;
var db = require('./db');

ZPOOL_NAME = 'zones'; 
DSAPI_URL  = 'https://datasets.joyent.com/datasets/'; // need trailing slash

CURL  = '/usr/bin/curl';
BZIP2 = '/usr/bin/bzip2';
GZIP  = '/usr/bin/gzip';
MOUNT = '/usr/sbin/mount';


var FILTER_FIELDS = [
  'name',
  'version',
  'uuid',
  'urn',
  'type',
  'description',
  'os',
  'published_at',
  'creator_uuid',
  'creator_name',
  'owner_uuid'
];


_isUuid = function(obj) {
  var uuidReg = /[a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12}/;
  if (typeof(obj) === 'string') {
    return (uuidReg.test(obj));
  } 
  return false;
}

_isUrn = function(obj) {
  var urnReg = /[a-z0-9-_]+:[a-z0-9]+:[a-z0-9._-]+:[a-z0-9._-]+/;
  if (typeof(obj) === 'string') {
    return (urnReg.test(obj));
  }
  return false;
}

_isUrl = function(obj) {
  if (typeof(obj) === 'string') {
    var o = url.parse(obj);
    if (o.host && o.protocol && o.pathname) 
      return true;
  }
  return false;
};

datasetExists = function(uuid, callback) {
  db.load(uuid, function(err, record) {
    if (err || record.uuid == undefined) { 
      callback(false);
    }
    else {
      callback(true);
    }
  })
}

httpOptions = function(manifestId, callback) {
  var opts;
  
  
  if (!manifestId) {
    opts = url.parse(DSAPI_URL);
  }
  else if (_isUrl(manifestId)) {
    opts = url.parse(manifestId);
  }
  else if (_isUuid(manifestId)) {
    opts = url.parse(DSAPI_URL + manifestId);
  } 
  else {
    throw new Error("options requires a URL or UUID");
  }
  
  opts.headers = {
    'accept': 'application/json'
  };
  
  // nodev4 fixup (url and http client reqs dont match)
  if (opts.pathname) {
    opts.path = opts.pathname; 
    opts.pathname = undefined;
  }
  if (opts.auth) {
  	var s = opts.host.split(/@/);
  	opts.host = s[s.length-1];
  	var auth = 'Basic ' + new Buffer(opts.auth).toString('base64');
  	opts.headers['Authorization'] = auth;
  }
 
  // SmartOS DNS is disabled by default. We rely on node to
  // resolve the host for us.
  dns.resolve4(opts.hostname, function(err, addresses) {
    if (err) throw new Error("could not resolve host: " + opts.hostname);
    // pick one at random?
    opts.host = addresses[0]; 
    callback(opts);
  });

}

httpClient = function(options) {
  var client;
  switch (options.protocol) {
    case 'https:':
      client = https;
      break;
    case 'http:':
      client = http;
      break;
  }
  return client;
}


// Todo just replace this with Array.filter and create
// a list of filter functions (ele, idx, arr)
filterResults = function(fields, toFilter) {
  var filterOn = FILTER_FIELDS;
  var results = [];

  for (var i=0; i<toFilter.length; i++) {
    var item = toFilter[i];
    var r = {};
    for (var f=0; f<filterOn.length; f++) {
      r[filterOn[f]] = item[filterOn[f]];
    }
    results.push(r);
  }

  return results;
}

// returns the manifest specified by 'manifestId <id>'
// The ID can be either a full URL, or a UUID. If only the
// UUID is provided, then the default Joyent Dataset API
// host is used. If the DSADM_URL environment variable is
// set then that is used. If a full URL is used then the 
// manifest at that url is used.

showRemote = function(manifestId, callback) {
  assert.ok(manifestId);
  assert.ok(callback);
 
  httpOptions(manifestId, function(options) {

    getSync(options, function(err, res) {
      if (err) callback(err);

      var manifest = JSON.parse(res.body);
      callback(null, manifest);
    });
  
  });

}

// LIST lists all datasets available from the dataset API.
// Results are passed through 'filterResults' prior to
// being sent to the callback.

listRemote = function(params, callback) {
  assert.ok(callback);
  
  httpOptions(null, function(options) {

    getSync(options, function(err, res) {
      if (err) callback(err);
      var list = JSON.parse(res.body);

      var results = filterResults(null, list);
      callback(null, results);
    });

  });

}

dumpLocal = function(name, callback) {
  assert.ok(name);
  assert.ok(callback);

  var result = {
    volume: {},
    children: {
      snapshots: [],
      clones: []
    },
    manifest: {}
  };
    
  onLoad = function(err, manifest) {
    if (err) return callback(err, null);
 
    result.manifest = manifest;
    var _name = ZPOOL_NAME + '/' + name;
 
    zfs.getRecursive(_name, function(err, snapshots) {

      var error;
      var n;
      
      result.volume = snapshots.shift();
      result.children.snapshots = snapshots;
      n = snapshots.length; 
      
      var cb_n = function(next) {
        return function() {
          --n || next(error, result);
        }
      };


      zfs.list(null, function (err, list) {
        if (err) return callback(err, null);
       
        var snapNames = snapshots.map(function(val) {
          return val.name;
        });
        
        for (i in list) {
          var d = list[i];
          if (snapNames.indexOf(d.origin) >= 0) {
            result.children.clones.push(d);
          }
        } 
        callback(error, result);
      });

    });

  };

  db.load(name, onLoad); 

}

// HTTP Get Synchronous
getSync = function(options, callback) {
  assert.ok(options);
  assert.ok(callback);

  var client = httpClient(options);

  req = client.request(options, function(res) {
 
    res.setEncoding('utf8');
    res.body = '';

    res.on('data', function(chunk) {
      res.body = res.body + chunk
    });

    res.on('end', function() {
      // TODO check content-length
      // TODO chech content-md5 
      callback(null, res);
    });

  });

  req.on('error', callback);
  req.end();
}

spawnInflater = function(type) {
  assert.ok(type);

  var inflater = null;
  var args = ['-cdfq'];

  switch(type) {
    case 'gz':
      inflater = spawn(GZIP, args); 
      break;
    case 'bz2':
      inflater = spawn(BZIP2, args);
      break;
    default:
      throw new Error("inflater type must be one of 'gz' or 'bz2'");
      break;
  }
 
  return inflater; 
}


var importDataset = function(mId, callback) {
  assert.ok(mId);
  assert.ok(callback);

  var _manifest;

  httpOptions(mId, function(options) {
	
    showRemote(mId, function(err, manifest) {
      if (err) callback(err);
      var _uuid, dsfile, _url;
      var inflater;
      
      _uuid = manifest.uuid;
      var valid = db.validateManifest(manifest);

			if (valid != true) {
			  return callback(valid); 
			}

      datasetExists(_uuid, function(exists) {
        if (exists) {
          callback("dataset already installed");
        }
        else {

					// The file to download is comprised of:
					// https://host/datasets/:uuid/:dsfile.path  
					dsfile = manifest.files[0];
					
					log.debug("%s urn: %s",               _uuid, manifest.urn);
					log.debug("%s size (bytes compressed): %s",  _uuid, dsfile.size);
					log.debug("%s checksum: (sha1) %s",   _uuid, dsfile.sha1);
					log.debug("%s path: %s",              _uuid, dsfile.path);

					zfs.getPool(ZPOOL_NAME, function(err, pool) {
						// zfs lib takes care of temporary imports
						var volname = ZPOOL_NAME + '/' + _uuid;
						var volnameTemp = volname + '-partial';
						var curl, zfsInl;
						var args = ['--insecure'];
						
						curlHost = function(options) {
							var auth = '';

							if (options.auth) auth = options.auth + "@"
							return options.protocol + '//' + auth + options.host + options.path;
						}
						
						saveManifest = function() {
							db.save(manifest, function(err) {
								if (err) return callback(err);
								log.info("%s successfully installed",  _uuid);
								callback(err, _uuid);
							});  
						}

						setUuidProp = function() {
							zfs.setProp(volname, "dsadm:uuid", _uuid, function(err) {
								if (err) return callback(err, _uuid);
								saveManifest()
							});
						}
						
						setUrnProp = function() {
							zfs.setProp(volname, "dsadm:urn", manifest.urn, function(err) {
								if (err) return callback(err, _uuid);
								setUuidProp();
							});
						}

						renameVolume = function() {
							zfs.rename(volnameTemp, volname, function(err) {
								if (err) return callback(err, _uuid);
								setUrnProp();
							});  
						}
				 
						downloadDataset = function() {
							if ( /\.gz$/.test(dsfile.path) ) {
								inflater = spawnInflater('gz');
							}
							else if (/\.bz2$/.test(dsfile.path)) {
								inflater = spawnInflater('bz2');
							}

							if (inflater) {
								log.debug("%s requires inflate stream", _uuid);

								inflater.stderr.on('data', function(chunk) {
									log.err("%s got inflater error: %s", _uuid, chunk.toString());
								}); 

								inflater.stdout.pipe(zfsIn.stdin);
								curl = spawn(CURL, args);
								curl.stdout.pipe(inflater.stdin);

							} 
							else {
								args.push(curlHost(options)); 
								curl = spawn(CURL_BIN, args);
								curl.stdout.pipe(zfsIn.stdin);
							}

						}
						
						log.info("%s doesnt exist. continuing with install", _uuid);
						log.debug("%s zpool has %sMB free", ZPOOL_NAME, pool.free);
						log.debug("%s importing to %s", _uuid, volname);
						log.debug("%s downloading file from: %s",  _uuid, options.hostname);
						
						zfsIn = zfs.spawnReceiveStream(volnameTemp);

						var dsPathReg = /.*\.dsmanifest$/
						if (dsPathReg.test(options.path)) {
							var p = options.path.split(/\//);
							p.pop();
							options.path = p.join('/') + '/' + dsfile.path;
						} 
						else {
							options.path = options.path + '/' + dsfile.path;
						}
						
						args.push(curlHost(options)); 
						
						downloadDataset();
          
						zfsIn.on('exit', function(code, signal) {
							if (code != 0) {
								log.debug("%s zfs recieve exited non-zero: %s", _uuid, code);
								return callback("zfs receive exited non zero: " + code, _uuid);
							} 
							else {
								renameVolume();
							}
						});
				
					});

        }
      });
    });
  });
}

destroyDataset = function(name, callback) {
  assert.ok(name);
  assert.ok(callback);


  dumpLocal(name, function(err, dump) {
    if (err) return callback(err);
    log.debug("%s checking number of children", name);
    var numClones = dump.children.clones.length;

    if (numClones > 0) {
      log.debug("%s has %s dependent clones. cannot destroy", name, numClones);
      return callback("dataset has children. cannot destroy");
    } 
    else {
      log.info("destroying dataset %s", name);
      zfs.destroy(dump.volume.name, {recursive: true}, function(err) {
        log.debug("%s destroying zfs volume", name);
        if (err) return callback(err);
        db.destroy(name, function(err) {
          log.debug("%s removing database record", name);
          callback(err);
        });
      });
    }
  });

};

module.exports = {
  importDataset: importDataset,
  destroyDataset: destroyDataset,
  listLocal: db.all,
  dumpLocal: dumpLocal,
  listRemote: listRemote,
  showRemote: showRemote,
}
